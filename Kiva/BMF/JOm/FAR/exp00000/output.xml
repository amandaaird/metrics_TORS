<experiment count="41">
  <!--DO NOT EDIT. File automatically generated by librec-auto-->
  <meta>
    <param>
      <name>user-reg</name>
      <value>0.09396034919138913</value>
    </param>
    <param>
      <name>item-reg</name>
      <value>0.12176224817518051</value>
    </param>
    <param>
      <name>bias-reg</name>
      <value>0.052065703515294055</value>
    </param>
    <param>
      <name>num-factors</name>
      <value>79</value>
    </param>
    <param>
      <name>lambda</name>
      <value>0.03270893594148662</value>
    </param>
  </meta>
  <statuses>
    <status>
      <message>Executing</message>
      <exp_no>41</exp_no>
      <date>2022-11-28 08:10:32.201487</date>
    </status>
    <status>
      <message>Completed</message>
      <date>2022-11-28 08:10:53.619008</date>
    </status>
    <status>
      <message>Python-side metrics completed</message>
      <date>2022-11-28 08:15:34.306830</date>
    </status>
    <status>
      <message>Executing</message>
      <date>2022-11-28 08:17:37.282979</date>
    </status>
    <status>
      <message>Completed</message>
      <date>2022-11-28 08:17:45.993602</date>
    </status>
    <status>
      <message>Python-side metrics completed</message>
      <date>2022-11-28 08:18:37.864096</date>
    </status>
    <status>
      <message>Executing</message>
      <date>2023-04-07 11:57:51.613288</date>
    </status>
    <status>
      <message>Completed</message>
      <date>2023-04-07 11:58:01.546812</date>
    </status>
    <status>
      <message>Python-side metrics completed</message>
      <date>2023-04-07 12:05:09.343415</date>
    </status>
  </statuses>
  <results>
    <folds>
      <cv id="1">
        <metric name="NormalizedDCGEvaluator">0.011762379240046241</metric>
        <metric name="PStatisticalParityEvaluator">-0.9988033298647245</metric>
        <metric name="kendall_tau.py">0.9986572340130392</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">0.9998488001109724</metric>
      </cv>
      <cv id="2">
        <metric name="NormalizedDCGEvaluator">0.013313192970552638</metric>
        <metric name="PStatisticalParityEvaluator">-0.9999480114374838</metric>
        <metric name="kendall_tau.py">0.9999334165626299</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">0.9999922319323068</metric>
      </cv>
      <cv id="3">
        <metric name="NormalizedDCGEvaluator">0.014620855907441279</metric>
        <metric name="PStatisticalParityEvaluator">-0.9989039665970777</metric>
        <metric name="kendall_tau.py">0.9999999999999998</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">1.0</metric>
      </cv>
      <cv id="4">
        <metric name="NormalizedDCGEvaluator">0.014048455065985734</metric>
        <metric name="PStatisticalParityEvaluator">-1.0</metric>
        <metric name="kendall_tau.py">0.9999999999999998</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">1.0</metric>
      </cv>
      <cv id="5">
        <metric name="NormalizedDCGEvaluator">0.013515674391990076</metric>
        <metric name="PStatisticalParityEvaluator">-1.0</metric>
        <metric name="kendall_tau.py">0.9999999999999998</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">1.0</metric>
      </cv>
    </folds>
    <averages/>
  </results>
</experiment>
