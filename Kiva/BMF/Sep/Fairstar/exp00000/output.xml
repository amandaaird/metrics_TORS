<experiment count="11">
  <!--DO NOT EDIT. File automatically generated by librec-auto-->
  <meta>
    <param>
      <name>alpha</name>
      <value>1</value>
    </param>
  </meta>
  <statuses>
    <status>
      <message>Executing</message>
      <exp_no>11</exp_no>
      <date>2022-11-10 17:59:31.946360</date>
    </status>
    <status>
      <message>Completed</message>
      <date>2022-11-10 17:59:46.457163</date>
    </status>
    <status>
      <message>Python-side metrics completed</message>
      <date>2022-11-10 18:59:29.053946</date>
    </status>
    <status>
      <message>Executing</message>
      <date>2022-11-10 20:37:47.983307</date>
    </status>
    <status>
      <message>Completed</message>
      <date>2022-11-10 20:37:53.475218</date>
    </status>
    <status>
      <message>Executing</message>
      <date>2022-11-10 20:50:36.565491</date>
    </status>
    <status>
      <message>Completed</message>
      <date>2022-11-10 20:50:42.111475</date>
    </status>
    <status>
      <message>Python-side metrics completed</message>
      <date>2022-11-10 21:01:31.426397</date>
    </status>
    <status>
      <message>Executing</message>
      <date>2022-12-12 04:25:42.208582</date>
    </status>
    <status>
      <message>Completed</message>
      <date>2022-12-12 04:26:10.293613</date>
    </status>
    <status>
      <message>Python-side metrics completed</message>
      <date>2022-12-12 05:27:26.646297</date>
    </status>
    <status>
      <message>Executing</message>
      <date>2023-04-07 12:28:37.115659</date>
    </status>
    <status>
      <message>Completed</message>
      <date>2023-04-07 12:28:47.678320</date>
    </status>
    <status>
      <message>Python-side metrics completed</message>
      <date>2023-04-07 12:36:12.125691</date>
    </status>
  </statuses>
  <results>
    <folds>
      <cv id="1">
        <metric name="NormalizedDCGEvaluator">0.014164543700387134</metric>
        <metric name="PStatisticalParityEvaluator">0.17325702393335318</metric>
        <metric name="kendall_tau.py">-0.06086281037591899</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">0.12359362305055188</metric>
      </cv>
      <cv id="2">
        <metric name="NormalizedDCGEvaluator">0.014946040167329947</metric>
        <metric name="PStatisticalParityEvaluator">0.4584871328307749</metric>
        <metric name="kendall_tau.py">0.06539048411707588</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">0.05719996829360125</metric>
      </cv>
      <cv id="3">
        <metric name="NormalizedDCGEvaluator">0.021991432405116126</metric>
        <metric name="PStatisticalParityEvaluator">-0.04572025052191281</metric>
        <metric name="kendall_tau.py">-0.1548675267027327</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">0.07786502982383132</metric>
      </cv>
      <cv id="4">
        <metric name="NormalizedDCGEvaluator">0.020490029852060523</metric>
        <metric name="PStatisticalParityEvaluator">0.2627684346700784</metric>
        <metric name="kendall_tau.py">-0.06947426827576642</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">0.10043763747696333</metric>
      </cv>
      <cv id="5">
        <metric name="NormalizedDCGEvaluator">0.020150164013936506</metric>
        <metric name="PStatisticalParityEvaluator">0.34883480062143946</metric>
        <metric name="kendall_tau.py">-0.12241919822444167</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">0.19749833541406575</metric>
      </cv>
    </folds>
    <averages/>
  </results>
</experiment>
