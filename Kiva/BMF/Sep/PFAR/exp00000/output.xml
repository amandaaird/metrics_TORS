<experiment count="9">
  <!--DO NOT EDIT. File automatically generated by librec-auto-->
  <meta>
    <param>
      <name>lambda</name>
      <value>0.9</value>
    </param>
    <param>
      <name>alpha</name>
      <value>0.0</value>
    </param>
  </meta>
  <statuses>
    <status>
      <message>Executing</message>
      <exp_no>9</exp_no>
      <date>2022-11-10 19:24:19.981543</date>
    </status>
    <status>
      <message>Completed</message>
      <date>2022-11-10 19:24:45.668218</date>
    </status>
    <status>
      <message>Executing</message>
      <date>2022-11-11 08:17:37.374578</date>
    </status>
    <status>
      <message>Completed</message>
      <date>2022-11-11 08:17:43.007739</date>
    </status>
    <status>
      <message>Executing</message>
      <date>2022-12-12 10:05:55.671964</date>
    </status>
    <status>
      <message>Completed</message>
      <date>2022-12-12 10:06:06.527595</date>
    </status>
    <status>
      <message>Executing</message>
      <date>2023-04-07 12:37:03.256350</date>
    </status>
    <status>
      <message>Completed</message>
      <date>2023-04-07 12:37:14.053634</date>
    </status>
    <status>
      <message>Python-side metrics completed</message>
      <date>2023-04-07 12:45:02.044657</date>
    </status>
  </statuses>
  <results>
    <folds>
      <cv id="1">
        <metric name="NormalizedDCGEvaluator">0.013230685104670832</metric>
        <metric name="PStatisticalParityEvaluator">-0.8789802289282225</metric>
        <metric name="kendall_tau.py">0.182976834512415</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">0.7900314785090066</metric>
      </cv>
      <cv id="2">
        <metric name="NormalizedDCGEvaluator">0.01376510089520623</metric>
        <metric name="PStatisticalParityEvaluator">-0.8772030153366486</metric>
        <metric name="kendall_tau.py">0.30864197530864196</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">0.7909901115668906</metric>
      </cv>
      <cv id="3">
        <metric name="NormalizedDCGEvaluator">0.01799316285966049</metric>
        <metric name="PStatisticalParityEvaluator">-0.883559498956181</metric>
        <metric name="kendall_tau.py">0.2431127756970453</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">0.7950468957453977</metric>
      </cv>
      <cv id="4">
        <metric name="NormalizedDCGEvaluator">0.01661151083245861</metric>
        <metric name="PStatisticalParityEvaluator">-0.8839327296248602</metric>
        <metric name="kendall_tau.py">0.35456235261478697</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">0.7927228266254482</metric>
      </cv>
      <cv id="5">
        <metric name="NormalizedDCGEvaluator">0.017576250712084046</metric>
        <metric name="PStatisticalParityEvaluator">-0.8920248575867623</metric>
        <metric name="kendall_tau.py">0.19495075599944509</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">0.7941696490497988</metric>
      </cv>
    </folds>
    <averages/>
  </results>
</experiment>
