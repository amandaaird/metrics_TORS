<study>
  <experiment_count>1</experiment_count>
  <completed_at>2023-04-07 11:29:11.588490</completed_at>
  <check>
    <message src="PFAR/LibRec-Auto_log.log">ERROR:root: Script failure: result_graphics.py: Post processing script at /Users/amandaaird/PycharmProjects/librec-auto/librec_auto/core/cmd/post/result_graphics.py failed.</message>
  </check>
  <experiments>
    <experiment count="39">
      <!--DO NOT EDIT. File automatically generated by librec-auto-->
      <meta>
        <param>
          <name>user-reg</name>
          <value>0.024986166998251597</value>
        </param>
        <param>
          <name>item-reg</name>
          <value>0.0686043866735774</value>
        </param>
        <param>
          <name>bias-reg</name>
          <value>0.13125354819681567</value>
        </param>
        <param>
          <name>num-factors</name>
          <value>29</value>
        </param>
        <param>
          <name>lambda</name>
          <value>0.8273437035184119</value>
        </param>
        <param>
          <name>alpha</name>
          <value>0.8762703795023521</value>
        </param>
      </meta>
      <results>
        <folds>
          <cv id="1">
            <metric name="NormalizedDCGEvaluator">0.01450108141515913</metric>
            <metric name="PStatisticalParityEvaluator">-0.8909469302809766</metric>
            <metric name="kendall_tau.py">0.2943265362741018</metric>
            <metric name="lowest_item_promoted.py">None</metric>
            <metric name="rank_biased_overlap.py">0.8007401561540137</metric>
          </cv>
          <cv id="2">
            <metric name="NormalizedDCGEvaluator">0.016557909530962298</metric>
            <metric name="PStatisticalParityEvaluator">-0.8936314010917793</metric>
            <metric name="kendall_tau.py">0.49423220973782767</metric>
            <metric name="lowest_item_promoted.py">None</metric>
            <metric name="rank_biased_overlap.py">0.7986164219329013</metric>
          </cv>
          <cv id="3">
            <metric name="NormalizedDCGEvaluator">0.017597655548063147</metric>
            <metric name="PStatisticalParityEvaluator">-0.8936325678497063</metric>
            <metric name="kendall_tau.py">0.42272159800249687</metric>
            <metric name="lowest_item_promoted.py">None</metric>
            <metric name="rank_biased_overlap.py">0.8052865366704318</metric>
          </cv>
          <cv id="4">
            <metric name="NormalizedDCGEvaluator">0.017476608534551914</metric>
            <metric name="PStatisticalParityEvaluator">-0.8934023285899291</metric>
            <metric name="kendall_tau.py">0.335685948120405</metric>
            <metric name="lowest_item_promoted.py">None</metric>
            <metric name="rank_biased_overlap.py">0.8005696549947486</metric>
          </cv>
          <cv id="5">
            <metric name="NormalizedDCGEvaluator">0.016614253900403476</metric>
            <metric name="PStatisticalParityEvaluator">-0.9003107198343006</metric>
            <metric name="kendall_tau.py">0.0912026633374948</metric>
            <metric name="lowest_item_promoted.py">None</metric>
            <metric name="rank_biased_overlap.py">0.8018795553177576</metric>
          </cv>
        </folds>
        <averages/>
      </results>
    </experiment>
  </experiments>
  <config>
    <random-seed>202110</random-seed>
    <!-- This is the configuration used to run the study. -->
    <thread-count>1</thread-count>
    <library src="system">default-algorithms.xml</library>
    <!-- DATA SECTION -->
    <data>
      <data-dir>../../../data</data-dir>
      <format>UIR</format>
      <data-file format="text">rating_5000_cls_hc_10core_iterative.csv</data-file>
    </data>
    <!-- FEATURES SECTION -->
    <features>
      <appender-class>net.librec.data.convertor.appender.ItemFeatureAppender</appender-class>
      <item-feature-file>loan_feature_df_hc_10core.csv</item-feature-file>
      <protected-feature name="fea:loan_buck_5" type="fea:loan_buck_5">loan_buck_5</protected-feature>
    </features>
    <!-- SPLITTER SECTION -->
    <splitter>
      <model count="5">kcv</model>
      <save>true</save>
    </splitter>
    <alg ref="alg:slim">

        </alg>
    <!-- METRICS SECTION -->
    <metric>
      <ranking>true</ranking>
      <list-size>50</list-size>
      <class>ndcg,psp</class>
      <protected-feature ref="fea:loan_buck_5"/>
      <script src="system" lang="python3">
        <script-name>kendall_tau.py</script-name>
        <param name="list_size">10</param>
      </script>
      <script src="system" lang="python3">
        <script-name>lowest_item_promoted.py</script-name>
        <param name="protected_feature">loan_buck_5</param>
        <param name="list_size">50</param>
      </script>
      <script src="system" lang="python3">
        <script-name>rank_biased_overlap.py</script-name>
        <param name="list_size">10</param>
      </script>
    </metric>
    <rerank>
      <script lang="python3" src="system">
        <script-name>fairstar_rerank.py</script-name>
        <param name="max_len">10</param>
        <param name="binary">False</param>
        <param name="protected_feature" ref="fea:loan_buck_5"/>
      </script>
    </rerank>
    <!-- POST-PROCESSING SECTION -->
    <post>
      <script lang="python3" src="system">
        <script-name>result_graphics.py</script-name>
        <param name="browser">true</param>
      </script>
      <script lang="python3" src="system">
        <script-name>results_to_csv.py</script-name>
        <param name="option">all</param>
      </script>
    </post>
  </config>
</study>
