<experiment count="47">
  <!--DO NOT EDIT. File automatically generated by librec-auto-->
  <meta>
    <param>
      <name>l1-reg</name>
      <value>0.5566948522267074</value>
    </param>
    <param>
      <name>l2-reg</name>
      <value>0.09255892259317261</value>
    </param>
    <param>
      <name>lambda</name>
      <value>0.10048241764452193</value>
    </param>
    <param>
      <name>alpha</name>
      <value>0.8576035839568763</value>
    </param>
  </meta>
  <statuses>
    <status>
      <message>Executing</message>
      <exp_no>47</exp_no>
      <date>2022-12-05 09:09:52.680723</date>
    </status>
    <status>
      <message>Completed</message>
      <date>2022-12-05 09:12:06.564978</date>
    </status>
    <status>
      <message>Python-side metrics completed</message>
      <date>2022-12-05 09:18:55.644828</date>
    </status>
    <status>
      <message>Executing</message>
      <date>2022-12-05 09:22:16.169730</date>
    </status>
    <status>
      <message>Completed</message>
      <date>2022-12-05 09:22:31.604908</date>
    </status>
    <status>
      <message>Python-side metrics completed</message>
      <date>2022-12-05 09:23:31.673034</date>
    </status>
    <status>
      <message>Executing</message>
      <date>2023-04-07 16:10:22.336464</date>
    </status>
    <status>
      <message>Completed</message>
      <date>2023-04-07 16:10:35.561992</date>
    </status>
    <status>
      <message>Python-side metrics completed</message>
      <date>2023-04-07 16:17:58.909100</date>
    </status>
  </statuses>
  <results>
    <folds>
      <cv id="1">
        <metric name="NormalizedDCGEvaluator">0.008483632238409165</metric>
        <metric name="PStatisticalParityEvaluator">-0.7737773152966017</metric>
        <metric name="kendall_tau.py">0.48677486475239284</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">0.8611233081663793</metric>
      </cv>
      <cv id="2">
        <metric name="NormalizedDCGEvaluator">0.008028801570325088</metric>
        <metric name="PStatisticalParityEvaluator">-0.7624642578633064</metric>
        <metric name="kendall_tau.py">0.5163268137050908</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">0.8670792858133682</metric>
      </cv>
      <cv id="3">
        <metric name="NormalizedDCGEvaluator">0.006863118991123688</metric>
        <metric name="PStatisticalParityEvaluator">-0.7694676409186176</metric>
        <metric name="kendall_tau.py">0.5066056318490776</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">0.8634765273566771</metric>
      </cv>
      <cv id="4">
        <metric name="NormalizedDCGEvaluator">0.007604941025961222</metric>
        <metric name="PStatisticalParityEvaluator">-0.7695213454075396</metric>
        <metric name="kendall_tau.py">0.5199223193230683</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">0.8694400749063671</metric>
      </cv>
      <cv id="5">
        <metric name="NormalizedDCGEvaluator">0.008337608810438803</metric>
        <metric name="PStatisticalParityEvaluator">-0.7703262558260342</metric>
        <metric name="kendall_tau.py">0.4979830767096684</metric>
        <metric name="lowest_item_promoted.py">None</metric>
        <metric name="rank_biased_overlap.py">0.8625336979569189</metric>
      </cv>
    </folds>
    <averages/>
  </results>
</experiment>
